{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from chart_studio import plotly as py\n",
    "import plotly.tools as tls\n",
    "from plotly.graph_objs import *\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# plotly.tools.set_credentials_file(username='', api_key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download, Load and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_18 = pd.read_csv(\"./data/Chicago_Crimes_2018.csv\")\n",
    "df_19 = pd.read_csv(\"./data/Chicago_Crimes_2019.csv\")\n",
    "df_20 = pd.read_csv(\"./data/Chicago_Crimes_2020.csv\")\n",
    "df_21 = pd.read_csv(\"./data/Chicago_Crimes_2021.csv\")\n",
    "df_22 = pd.read_csv(\"./data/Chicago_Crimes_2022.csv\")\n",
    "df_23 = pd.read_csv(\"./data/Chicago_Crimes_2023.csv\")\n",
    "df_raw = pd.concat([df_18, df_19, df_20, df_21, df_22, df_23], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Case Number', 'Date', 'Block', 'IUCR', 'Primary Type',\n",
       "       'Description', 'Location Description', 'Arrest', 'Domestic', 'Beat',\n",
       "       'District', 'Ward', 'Community Area', 'FBI Code', 'X Coordinate',\n",
       "       'Y Coordinate', 'Year', 'Updated On', 'Latitude', 'Longitude',\n",
       "       'Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_columns = ['Date', 'Latitude', 'Longitude', 'Arrest']\n",
    "df = df_raw[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Arrest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/09/2018 12:00:00 AM</td>\n",
       "      <td>41.911574</td>\n",
       "      <td>-87.789972</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/15/2018 08:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/30/2018 01:05:00 PM</td>\n",
       "      <td>41.694643</td>\n",
       "      <td>-87.661565</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/01/2018 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/14/2018 02:45:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date   Latitude  Longitude  Arrest\n",
       "0  11/09/2018 12:00:00 AM  41.911574 -87.789972   False\n",
       "1  09/15/2018 08:00:00 AM        NaN        NaN    True\n",
       "2  09/30/2018 01:05:00 PM  41.694643 -87.661565   False\n",
       "3  09/01/2018 12:00:00 AM        NaN        NaN   False\n",
       "4  12/14/2018 02:45:00 PM        NaN        NaN   False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,373,071 total crime records\n"
     ]
    }
   ],
   "source": [
    "print(\"{:,} total crime records\".format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,360,210 total crime records after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(\"{:,} total crime records after removing duplicates\".format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break up date into components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_up_date(str_date):\n",
    "    date_format = '%m/%d/%Y %I:%M:%S %p'\n",
    "    date = datetime.strptime(str_date, date_format)\n",
    "    return date\n",
    "\n",
    "years = []\n",
    "months = []\n",
    "days = []\n",
    "hours = []\n",
    "minutes = []\n",
    "for date in map(break_up_date,df['Date']):\n",
    "    years.append(date.year)\n",
    "    months.append(date.month)\n",
    "    days.append(date.day)\n",
    "    hours.append(date.hour)\n",
    "    minutes.append(date.minute)\n",
    "df['Year'] = years\n",
    "df['Month'] = months\n",
    "df['Day'] =  days\n",
    "df['Hour'] = hours\n",
    "df['Minute'] = minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('Date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,340,842 total crime records after removing NAs\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=0,how='any', inplace=True)\n",
    "print(\"{:,} total crime records after removing NAs\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/09/2018 12:00:00 AM</td>\n",
       "      <td>41.911574</td>\n",
       "      <td>-87.789972</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/30/2018 01:05:00 PM</td>\n",
       "      <td>41.694643</td>\n",
       "      <td>-87.661565</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01/01/2018 12:01:00 AM</td>\n",
       "      <td>41.998188</td>\n",
       "      <td>-87.697224</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>09/01/2018 11:49:00 AM</td>\n",
       "      <td>41.872699</td>\n",
       "      <td>-87.688629</td>\n",
       "      <td>True</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>05/01/2018 12:00:00 AM</td>\n",
       "      <td>41.764193</td>\n",
       "      <td>-87.652879</td>\n",
       "      <td>False</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date   Latitude  Longitude  Arrest  Year  Month  Day  \\\n",
       "0   11/09/2018 12:00:00 AM  41.911574 -87.789972   False  2018     11    9   \n",
       "2   09/30/2018 01:05:00 PM  41.694643 -87.661565   False  2018      9   30   \n",
       "10  01/01/2018 12:01:00 AM  41.998188 -87.697224   False  2018      1    1   \n",
       "11  09/01/2018 11:49:00 AM  41.872699 -87.688629    True  2018      9    1   \n",
       "16  05/01/2018 12:00:00 AM  41.764193 -87.652879   False  2018      5    1   \n",
       "\n",
       "    Hour  Minute  \n",
       "0      0       0  \n",
       "2     13       5  \n",
       "10     0       1  \n",
       "11    11      49  \n",
       "16     0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# df[\"Arrest\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>1340842.0</td>\n",
       "      <td>41.843570</td>\n",
       "      <td>0.087499</td>\n",
       "      <td>36.619446</td>\n",
       "      <td>41.767920</td>\n",
       "      <td>41.861563</td>\n",
       "      <td>41.906392</td>\n",
       "      <td>42.022671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>1340842.0</td>\n",
       "      <td>-87.669593</td>\n",
       "      <td>0.059803</td>\n",
       "      <td>-91.686566</td>\n",
       "      <td>-87.711952</td>\n",
       "      <td>-87.663048</td>\n",
       "      <td>-87.627298</td>\n",
       "      <td>-87.524529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1340842.0</td>\n",
       "      <td>2020.319079</td>\n",
       "      <td>1.711073</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>1340842.0</td>\n",
       "      <td>6.396638</td>\n",
       "      <td>3.301088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>1340842.0</td>\n",
       "      <td>15.567696</td>\n",
       "      <td>8.856577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>1340842.0</td>\n",
       "      <td>12.782869</td>\n",
       "      <td>6.746426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minute</th>\n",
       "      <td>1340842.0</td>\n",
       "      <td>19.860324</td>\n",
       "      <td>18.708079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count         mean        std          min          25%  \\\n",
       "Latitude   1340842.0    41.843570   0.087499    36.619446    41.767920   \n",
       "Longitude  1340842.0   -87.669593   0.059803   -91.686566   -87.711952   \n",
       "Year       1340842.0  2020.319079   1.711073  2018.000000  2019.000000   \n",
       "Month      1340842.0     6.396638   3.301088     1.000000     4.000000   \n",
       "Day        1340842.0    15.567696   8.856577     1.000000     8.000000   \n",
       "Hour       1340842.0    12.782869   6.746426     0.000000     8.000000   \n",
       "Minute     1340842.0    19.860324  18.708079     0.000000     0.000000   \n",
       "\n",
       "                   50%          75%          max  \n",
       "Latitude     41.861563    41.906392    42.022671  \n",
       "Longitude   -87.663048   -87.627298   -87.524529  \n",
       "Year       2020.000000  2022.000000  2023.000000  \n",
       "Month         6.000000     9.000000    12.000000  \n",
       "Day          15.000000    23.000000    31.000000  \n",
       "Hour         14.000000    18.000000    23.000000  \n",
       "Minute       18.000000    33.000000    59.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 277.25x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=500)\n",
    "sns.FacetGrid(df, hue=\"Arrest\",hue_kws=dict(marker=[\"o\", \".\"])).map(plt.scatter,\"Longitude\",\"Latitude\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert df data to array type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = np.asarray(df[['Arrest']])\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "\n",
    "X = df[['Latitude','Longitude','Month','Day','Hour','Minute']]\n",
    "X = X.to_dict(orient='records')\n",
    "vec = DictVectorizer()\n",
    "X = vec.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each target from unbalanced dataset: [(0, 1125417), (1, 215425)] (arrest true (1) or false (0))\n",
      "Count of each target from balanced dataset: [(0, 668577), (1, 697274)] (arrest true (1) or false (0))\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of each target from unbalanced dataset: {} (arrest true (1) or false (0))\".format(sorted(Counter(y).items())))\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "print(\"Count of each target from balanced dataset: {} (arrest true (1) or false (0))\".format(sorted(Counter(y_resampled).items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train2 = scaler.fit_transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grid Search Modeling, Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning:\n",
      "\n",
      "Rounding errors prevent the line search from converging\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning:\n",
      "\n",
      "Rounding errors prevent the line search from converging\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\major_project_work\\location_based_safety_predictor\\crime_model.ipynb Cell 31\u001b[0m line \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/major_project_work/location_based_safety_predictor/crime_model.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lr \u001b[39m=\u001b[39m LogisticRegression();\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/major_project_work/location_based_safety_predictor/crime_model.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m grid_lr \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mlr,param_grid\u001b[39m=\u001b[39mparameters, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m);\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/major_project_work/location_based_safety_predictor/crime_model.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m grid_lr\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n\u001b[0;32m    841\u001b[0m         X,\n\u001b[0;32m    842\u001b[0m         y,\n\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    849\u001b[0m     )\n\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1589\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1588\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1589\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m   1590\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m   1591\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1592\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer),\n\u001b[0;32m   1593\u001b[0m )(\n\u001b[0;32m   1594\u001b[0m     path_func(\n\u001b[0;32m   1595\u001b[0m         X,\n\u001b[0;32m   1596\u001b[0m         y,\n\u001b[0;32m   1597\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1598\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1599\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1600\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1601\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1602\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1603\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1604\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1605\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1606\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1607\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1608\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1609\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1610\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1611\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1612\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1613\u001b[0m     )\n\u001b[0;32m   1614\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1615\u001b[0m )\n\u001b[0;32m   1617\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:823\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39melif\u001b[39;00m solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    822\u001b[0m     args \u001b[39m=\u001b[39m (X, target, \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C, sample_weight)\n\u001b[1;32m--> 823\u001b[0m     w0, n_iter_i \u001b[39m=\u001b[39m _newton_cg(\n\u001b[0;32m    824\u001b[0m         hess, func, grad, w0, args\u001b[39m=\u001b[39;49margs, maxiter\u001b[39m=\u001b[39;49mmax_iter, tol\u001b[39m=\u001b[39;49mtol\n\u001b[0;32m    825\u001b[0m     )\n\u001b[0;32m    826\u001b[0m \u001b[39melif\u001b[39;00m solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    827\u001b[0m     coef_, intercept_, n_iter_i, \u001b[39m=\u001b[39m _fit_liblinear(\n\u001b[0;32m    828\u001b[0m         X,\n\u001b[0;32m    829\u001b[0m         target,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    840\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    841\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:199\u001b[0m, in \u001b[0;36m_newton_cg\u001b[1;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m line_search:\n\u001b[0;32m    198\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m         alphak, fc, gc, old_fval, old_old_fval, gfkp1 \u001b[39m=\u001b[39m _line_search_wolfe12(\n\u001b[0;32m    200\u001b[0m             func, grad, xk, xsupi, fgrad, old_fval, old_old_fval, args\u001b[39m=\u001b[39;49margs\n\u001b[0;32m    201\u001b[0m         )\n\u001b[0;32m    202\u001b[0m     \u001b[39mexcept\u001b[39;00m _LineSearchError:\n\u001b[0;32m    203\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mLine Search failed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:39\u001b[0m, in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_line_search_wolfe12\u001b[39m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     28\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m    Same as line_search_wolfe1, but fall back to line_search_wolfe2 if\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    suitable step length is not found, and raise an exception if a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     ret \u001b[39m=\u001b[39m line_search_wolfe1(f, fprime, xk, pk, gfk, old_fval, old_old_fval, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m ret[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[39m# line search failed: try different one.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m         ret \u001b[39m=\u001b[39m line_search_wolfe2(\n\u001b[0;32m     44\u001b[0m             f, fprime, xk, pk, gfk, old_fval, old_old_fval, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m     45\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:96\u001b[0m, in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(gval[\u001b[39m0\u001b[39m], pk)\n\u001b[0;32m     94\u001b[0m derphi0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(gfk, pk)\n\u001b[1;32m---> 96\u001b[0m stp, fval, old_fval \u001b[39m=\u001b[39m scalar_search_wolfe1(\n\u001b[0;32m     97\u001b[0m         phi, derphi, old_fval, old_old_fval, derphi0,\n\u001b[0;32m     98\u001b[0m         c1\u001b[39m=\u001b[39;49mc1, c2\u001b[39m=\u001b[39;49mc2, amax\u001b[39m=\u001b[39;49mamax, amin\u001b[39m=\u001b[39;49mamin, xtol\u001b[39m=\u001b[39;49mxtol)\n\u001b[0;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m stp, fc[\u001b[39m0\u001b[39m], gc[\u001b[39m0\u001b[39m], fval, old_fval, gval[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:172\u001b[0m, in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m task[:\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    171\u001b[0m     alpha1 \u001b[39m=\u001b[39m stp\n\u001b[1;32m--> 172\u001b[0m     phi1 \u001b[39m=\u001b[39m phi(stp)\n\u001b[0;32m    173\u001b[0m     derphi1 \u001b[39m=\u001b[39m derphi(stp)\n\u001b[0;32m    174\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:84\u001b[0m, in \u001b[0;36mline_search_wolfe1.<locals>.phi\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mphi\u001b[39m(s):\n\u001b[0;32m     83\u001b[0m     fc[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m f(xk \u001b[39m+\u001b[39;49m s\u001b[39m*\u001b[39;49mpk, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:167\u001b[0m, in \u001b[0;36m_logistic_loss\u001b[1;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    164\u001b[0m     sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m    166\u001b[0m \u001b[39m# Logistic loss is the negative of the log of the logistic function.\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m out \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum(sample_weight \u001b[39m*\u001b[39m log_logistic(yz)) \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m alpha \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(w, w)\n\u001b[0;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:795\u001b[0m, in \u001b[0;36mlog_logistic\u001b[1;34m(X, out)\u001b[0m\n\u001b[0;32m    792\u001b[0m _log_logistic_sigmoid(n_samples, n_features, X, out)\n\u001b[0;32m    794\u001b[0m \u001b[39mif\u001b[39;00m is_1d:\n\u001b[1;32m--> 795\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msqueeze(out)\n\u001b[0;32m    796\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameters = { \n",
    "#     'C': np.power(10.0, np.arange(-10, 10)),\n",
    "#     'solver': ['newton-cg','lbfgs','saga'],\n",
    "#     'class_weight' : ['balanced','dict']\n",
    "# }\n",
    "# lr = LogisticRegression();\n",
    "# grid_lr = GridSearchCV(estimator=lr,param_grid=parameters, verbose=0);\n",
    "# grid_lr.fit(X_train, y_train);\n",
    "\n",
    "clr = LogisticRegression().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_lr.best_params_)\n",
    "print(grid_lr.best_score_)\n",
    "print(grid_lr.best_estimator_)\n",
    "# print(grid_lr.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'C': 1e-05, 'solver': 'saga', 'class_weight': 'dict'}\n",
    "0.71687847166966\n",
    "LogisticRegression(C=1e-05, class_weight='dict', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='saga', tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_lr.best_estimator_.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.5118735151242262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.51    273171\n",
      "   macro avg       0.26      0.50      0.34    273171\n",
      "weighted avg       0.26      0.51      0.35    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[     0 133342]\n",
      " [     0 139829]]\n",
      "Accuracy=0.5118735151242262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.51    273171\n",
      "   macro avg       0.26      0.50      0.34    273171\n",
      "weighted avg       0.26      0.51      0.35    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[     0 133342]\n",
      " [     0 139829]]\n",
      "Accuracy=0.5118735151242262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.51    273171\n",
      "   macro avg       0.26      0.50      0.34    273171\n",
      "weighted avg       0.26      0.51      0.35    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[     0 133342]\n",
      " [     0 139829]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\major_project_work\\location_based_safety_predictor\\crime_model.ipynb Cell 35\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/major_project_work/location_based_safety_predictor/crime_model.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mtimeit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlr = LogisticRegression(C=1e-05, class_weight=\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39mdict\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m, dual=False,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m          fit_intercept=True, intercept_scaling=1, max_iter=100,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m          multi_class=\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39movr\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m, n_jobs=1, penalty=\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39ml2\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m, random_state=None,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m          solver=\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39msaga\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m, tol=0.0001, verbose=0, warm_start=False);\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mlr.fit(X_train2,y_train)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mlr_expected = y_test\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mlr_predicted = lr.predict(X_test)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mlr_cm = metrics.confusion_matrix(lr_expected, lr_predicted)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mprint(\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAccuracy=\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.format(metrics.accuracy_score(lr_expected, lr_predicted)))\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mprint(\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mClassification report for classifier \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m      \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m (\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mLogistic Regression\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m, metrics.classification_report(lr_expected, lr_predicted)))\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mprint(\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mConfusion matrix:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m% lr\u001b[39;49;00m\u001b[39m_cm)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2347\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2345\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2346\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2347\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2348\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1166\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[39mif\u001b[39;00m time_number \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m:\n\u001b[0;32m   1164\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m all_runs \u001b[39m=\u001b[39m timer\u001b[39m.\u001b[39;49mrepeat(repeat, number)\n\u001b[0;32m   1167\u001b[0m best \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(all_runs) \u001b[39m/\u001b[39m number\n\u001b[0;32m   1168\u001b[0m worst \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(all_runs) \u001b[39m/\u001b[39m number\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\timeit.py:205\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    203\u001b[0m r \u001b[39m=\u001b[39m []\n\u001b[0;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(repeat):\n\u001b[1;32m--> 205\u001b[0m     t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeit(number)\n\u001b[0;32m    206\u001b[0m     r\u001b[39m.\u001b[39mappend(t)\n\u001b[0;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    154\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[0;32m    155\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[0;32m    157\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:5\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1589\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1588\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1589\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m   1590\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m   1591\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1592\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer),\n\u001b[0;32m   1593\u001b[0m )(\n\u001b[0;32m   1594\u001b[0m     path_func(\n\u001b[0;32m   1595\u001b[0m         X,\n\u001b[0;32m   1596\u001b[0m         y,\n\u001b[0;32m   1597\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1598\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1599\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1600\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1601\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1602\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1603\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1604\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1605\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1606\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1607\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1608\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1609\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1610\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1611\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1612\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1613\u001b[0m     )\n\u001b[0;32m   1614\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1615\u001b[0m )\n\u001b[0;32m   1617\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:864\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    861\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[0;32m    862\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[1;32m--> 864\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[0;32m    865\u001b[0m         X,\n\u001b[0;32m    866\u001b[0m         target,\n\u001b[0;32m    867\u001b[0m         sample_weight,\n\u001b[0;32m    868\u001b[0m         loss,\n\u001b[0;32m    869\u001b[0m         alpha,\n\u001b[0;32m    870\u001b[0m         beta,\n\u001b[0;32m    871\u001b[0m         max_iter,\n\u001b[0;32m    872\u001b[0m         tol,\n\u001b[0;32m    873\u001b[0m         verbose,\n\u001b[0;32m    874\u001b[0m         random_state,\n\u001b[0;32m    875\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    876\u001b[0m         max_squared_sum,\n\u001b[0;32m    877\u001b[0m         warm_start_sag,\n\u001b[0;32m    878\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    879\u001b[0m     )\n\u001b[0;32m    881\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    882\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    883\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[0;32m    885\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:327\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    322\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    323\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    326\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[1;32m--> 327\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[0;32m    328\u001b[0m     dataset,\n\u001b[0;32m    329\u001b[0m     coef_init,\n\u001b[0;32m    330\u001b[0m     intercept_init,\n\u001b[0;32m    331\u001b[0m     n_samples,\n\u001b[0;32m    332\u001b[0m     n_features,\n\u001b[0;32m    333\u001b[0m     n_classes,\n\u001b[0;32m    334\u001b[0m     tol,\n\u001b[0;32m    335\u001b[0m     max_iter,\n\u001b[0;32m    336\u001b[0m     loss,\n\u001b[0;32m    337\u001b[0m     step_size,\n\u001b[0;32m    338\u001b[0m     alpha_scaled,\n\u001b[0;32m    339\u001b[0m     beta_scaled,\n\u001b[0;32m    340\u001b[0m     sum_gradient_init,\n\u001b[0;32m    341\u001b[0m     gradient_memory_init,\n\u001b[0;32m    342\u001b[0m     seen_init,\n\u001b[0;32m    343\u001b[0m     num_seen_init,\n\u001b[0;32m    344\u001b[0m     fit_intercept,\n\u001b[0;32m    345\u001b[0m     intercept_sum_gradient,\n\u001b[0;32m    346\u001b[0m     intercept_decay,\n\u001b[0;32m    347\u001b[0m     is_saga,\n\u001b[0;32m    348\u001b[0m     verbose,\n\u001b[0;32m    349\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[0;32m    352\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    353\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    354\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    355\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "lr = LogisticRegression(C=1e-05, class_weight='dict', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='saga', tol=0.0001, verbose=0, warm_start=False);\n",
    "lr.fit(X_train2,y_train)\n",
    "lr_expected = y_test\n",
    "lr_predicted = lr.predict(X_test)\n",
    "lr_cm = metrics.confusion_matrix(lr_expected, lr_predicted)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(lr_expected, lr_predicted)))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (\"Logistic Regression\", metrics.classification_report(lr_expected, lr_predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % lr_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\major_project_work\\location_based_safety_predictor\\crime_model.ipynb Cell 36\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/major_project_work/location_based_safety_predictor/crime_model.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mtimeit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlr_expected = y_test\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mlr_predicted = lr.predict(X_test)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mlr_cm = metrics.confusion_matrix(lr_expected, lr_predicted)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mprint(\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAccuracy=\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.format(metrics.accuracy_score(lr_expected, lr_predicted)))\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mprint(\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mClassification report for classifier \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m      \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m (\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mLogistic Regression\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m, metrics.classification_report(lr_expected, lr_predicted)))\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mprint(\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mConfusion matrix:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m% lr\u001b[39;49;00m\u001b[39m_cm)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2347\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2345\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2346\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2347\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2348\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1162\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[0;32m   1161\u001b[0m     number \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m index\n\u001b[1;32m-> 1162\u001b[0m     time_number \u001b[39m=\u001b[39m timer\u001b[39m.\u001b[39;49mtimeit(number)\n\u001b[0;32m   1163\u001b[0m     \u001b[39mif\u001b[39;00m time_number \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m:\n\u001b[0;32m   1164\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    154\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[0;32m    155\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[0;32m    157\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:2\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    412\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m    426\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    427\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:405\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    387\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39m    Predict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[39m        this class would be predicted.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    407\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    408\u001b[0m     scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Users\\soumy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1217\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[0;32m   1218\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1219\u001b[0m     ]\n\u001b[0;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1222\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "lr_expected = y_test\n",
    "lr_predicted = lr.predict(X_test)\n",
    "lr_cm = metrics.confusion_matrix(lr_expected, lr_predicted)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(lr_expected, lr_predicted)))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (\"Logistic Regression\", metrics.classification_report(lr_expected, lr_predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % lr_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lr_cm,classes=[0,1],cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = { \n",
    "    'n_neighbors':[5,7,9],\n",
    "    'weights':['uniform', 'distance']\n",
    "}\n",
    "knn = KNeighborsClassifier();\n",
    "grid_knn = GridSearchCV(estimator=knn, param_grid=parameters, verbose=0);\n",
    "grid_knn.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.953401727861771\n",
      "KNeighborsClassifier(weights='distance')\n"
     ]
    }
   ],
   "source": [
    "print(grid_knn.best_params_)\n",
    "print(grid_knn.best_score_)\n",
    "print(grid_knn.best_estimator_)\n",
    "# print(grid_lr.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_neighbors': 5, 'weights': 'distance'}\n",
    "0.8260319336773744\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_knn.best_estimator_.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.5174744024804976\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.01      0.03    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.52    273171\n",
      "   macro avg       0.70      0.51      0.35    273171\n",
      "weighted avg       0.70      0.52      0.36    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1743 131599]\n",
      " [   213 139616]]\n",
      "Accuracy=0.5174744024804976\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.01      0.03    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.52    273171\n",
      "   macro avg       0.70      0.51      0.35    273171\n",
      "weighted avg       0.70      0.52      0.36    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1743 131599]\n",
      " [   213 139616]]\n",
      "Accuracy=0.5174744024804976\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.01      0.03    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.52    273171\n",
      "   macro avg       0.70      0.51      0.35    273171\n",
      "weighted avg       0.70      0.52      0.36    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1743 131599]\n",
      " [   213 139616]]\n",
      "Accuracy=0.5174744024804976\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.01      0.03    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.52    273171\n",
      "   macro avg       0.70      0.51      0.35    273171\n",
      "weighted avg       0.70      0.52      0.36    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1743 131599]\n",
      " [   213 139616]]\n",
      "Accuracy=0.5174744024804976\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.01      0.03    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.52    273171\n",
      "   macro avg       0.70      0.51      0.35    273171\n",
      "weighted avg       0.70      0.52      0.36    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1743 131599]\n",
      " [   213 139616]]\n",
      "Accuracy=0.5174744024804976\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.01      0.03    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.52    273171\n",
      "   macro avg       0.70      0.51      0.35    273171\n",
      "weighted avg       0.70      0.52      0.36    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1743 131599]\n",
      " [   213 139616]]\n",
      "Accuracy=0.5174744024804976\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.01      0.03    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.52    273171\n",
      "   macro avg       0.70      0.51      0.35    273171\n",
      "weighted avg       0.70      0.52      0.36    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1743 131599]\n",
      " [   213 139616]]\n",
      "Accuracy=0.5174744024804976\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.01      0.03    133342\n",
      "           1       0.51      1.00      0.68    139829\n",
      "\n",
      "    accuracy                           0.52    273171\n",
      "   macro avg       0.70      0.51      0.35    273171\n",
      "weighted avg       0.70      0.52      0.36    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1743 131599]\n",
      " [   213 139616]]\n",
      "17.5 s ± 6.39 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='distance');\n",
    "knn.fit(X_train2,y_train)\n",
    "\n",
    "knn_expected = y_test\n",
    "knn_predicted = knn.predict(X_test)\n",
    "knn_cm = metrics.confusion_matrix(knn_expected, knn_predicted)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(knn_expected, knn_predicted)))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (\"Logistic Regression\", metrics.classification_report(knn_expected, knn_predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % knn_cm)\n",
    "# plot_confusion_matrix(knn_cm,classes=[0,1],cmap=plt.cm.Reds)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn_cm,classes=[0,1],cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2023-10-08 12:12:22.899996\n",
      "Stop learning 2023-10-08 12:48:24.131849\n",
      "Elapsed learning 0:36:01.231853\n"
     ]
    }
   ],
   "source": [
    "parameters = { \n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2,4,5,6,7,8,9,10], \n",
    "    'min_samples_leaf':[2,4,6,8,10]\n",
    "}\n",
    "dt = DecisionTreeClassifier();\n",
    "dt_start_time = datetime.now()\n",
    "print('Start learning at {}'.format(str(dt_start_time)))\n",
    "grid_dt = GridSearchCV(estimator=dt, param_grid=parameters, verbose=0);\n",
    "grid_dt.fit(X_train, y_train);\n",
    "dt_end_time = datetime.now() \n",
    "print('Stop learning {}'.format(str(dt_end_time)))\n",
    "dt_elapsed_time= dt_end_time - dt_start_time\n",
    "print('Elapsed learning {}'.format(str(dt_elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 4}\n",
      "0.827490207563056\n",
      "DecisionTreeClassifier(max_features='auto', min_samples_leaf=10,\n",
      "                       min_samples_split=4)\n"
     ]
    }
   ],
   "source": [
    "print(grid_dt.best_params_)\n",
    "print(grid_dt.best_score_)\n",
    "print(grid_dt.best_estimator_)\n",
    "# print(grid_lr.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'max_features': 'auto', 'min_samples_split': 7, 'min_samples_leaf': 10}\n",
    "0.8439008494934109\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=10, min_samples_split=7,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_dt.best_estimator_.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing at 2023-10-08 12:49:35.408317\n",
      "Stop testing 2023-10-08 12:49:35.529100\n",
      "Elapsed testing 0:00:00.120783\n"
     ]
    }
   ],
   "source": [
    "dt_expected = y_test\n",
    "dt_start_time_test = datetime.now()\n",
    "print('Start testing at {}'.format(str(dt_start_time_test)))\n",
    "dt_predicted = grid_dt.best_estimator_.predict(X_test)\n",
    "dt_end_time_test = datetime.now() \n",
    "print('Stop testing {}'.format(str(dt_end_time_test)))\n",
    "dt_elapsed_time_test = dt_end_time_test - dt_start_time_test\n",
    "print('Elapsed testing {}'.format(str(dt_elapsed_time_test)))\n",
    "dt_cm = metrics.confusion_matrix(dt_expected, dt_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.8269069557163827\n",
      "Classification report for classifier Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82    133342\n",
      "           1       0.84      0.82      0.83    139829\n",
      "\n",
      "    accuracy                           0.83    273171\n",
      "   macro avg       0.83      0.83      0.83    273171\n",
      "weighted avg       0.83      0.83      0.83    273171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[110732  22610]\n",
      " [ 24674 115155]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy={}\".format(metrics.accuracy_score(dt_expected, dt_predicted)))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (\"Logistic Regression\", metrics.classification_report(dt_expected, dt_predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % dt_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(dt_cm,classes=[0,1],cmap=plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { \n",
    "    'criterion':['gini','entropy'],\n",
    "    'n_estimators':[10,15,20,25,30],\n",
    "    'min_samples_leaf':[1,2,3],\n",
    "    'min_samples_split':[3,4,5,6,7]\n",
    "}\n",
    "rf = RandomForestClassifier();\n",
    "rf_start_time = datetime.now()\n",
    "print('Start learning at {}'.format(str(rf_start_time)))\n",
    "grid_rf = GridSearchCV(estimator=rf, param_grid=parameters, verbose=0);\n",
    "grid_rf.fit(X_train, y_train);\n",
    "rf_end_time = datetime.now() \n",
    "print('Stop learning {}'.format(str(rf_end_time)))\n",
    "rf_elapsed_time= rf_end_time - rf_start_time\n",
    "print('Elapsed learning {}'.format(str(rf_elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_rf.best_params_)\n",
    "print(grid_rf.best_score_)\n",
    "print(grid_rf.best_estimator_)\n",
    "# print(grid_lr.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'min_samples_split': 3, 'n_estimators': 30, 'criterion': 'entropy', 'min_samples_leaf': 1}\n",
    "0.8902630322595312\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=3,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_rf.best_estimator_.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_expected = y_test\n",
    "rf_start_time_test = datetime.now()\n",
    "print('Start testing at {}'.format(str(rf_start_time_test)))\n",
    "rf_predicted = grid_rf.best_estimator_.predict(X_test)\n",
    "rf_end_time_test = datetime.now() \n",
    "print('Stop testing {}'.format(str(rf_end_time_test)))\n",
    "rf_elapsed_time_test = rf_end_time_test - rf_start_time_test\n",
    "print('Elapsed testing {}'.format(str(rf_elapsed_time_test)))\n",
    "rf_cm = metrics.confusion_matrix(rf_expected, rf_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy={}\".format(metrics.accuracy_score(rf_expected, rf_predicted)))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (\"Logistic Regression\", metrics.classification_report(rf_expected, rf_predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % rf_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rf_cm,classes=[0,1],cmap=plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { \n",
    "    'max_depth' : [10],\n",
    "    'n_estimators': [100,200],\n",
    "    'booster': ['gbtree']\n",
    "}\n",
    "xgb = XGBClassifier();\n",
    "xgb_start_time = datetime.now()\n",
    "print('Start learning at {}'.format(str(xgb_start_time)))\n",
    "grid_xgb = GridSearchCV(estimator=xgb, param_grid=parameters, verbose=0);\n",
    "grid_xgb.fit(X_train, y_train);\n",
    "xgb_end_time = datetime.now() \n",
    "print('Stop learning {}'.format(str(xgb_end_time)))\n",
    "xgb_elapsed_time= xgb_end_time - xgb_start_time\n",
    "print('Elapsed learning {}'.format(str(xgb_elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_xgb.best_params_)\n",
    "print(grid_xgb.best_score_)\n",
    "print(grid_xgb.best_estimator_)\n",
    "# print(grid_xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 200, 'max_depth': 10, 'booster': 'gbtree'}\n",
    "0.9251559172785899\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=10, min_child_weight=1, missing=None, n_estimators=200,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_xgb.best_estimator_.fit(X_train2, y_train2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=200,max_depth=10,booster='gbtree');\n",
    "xgb.fit(X_train2, y_train);\n",
    "xgb_expected = y_test\n",
    "xgb_predicted = xgb.predict(X_test2)\n",
    "xgb_cm = metrics.confusion_matrix(xgb_expected, xgb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_expected = y_test\n",
    "xgb_start_time_test = datetime.now()\n",
    "print('Start testing at {}'.format(str(xgb_start_time_test)))\n",
    "xgb_predicted = xgb.predict(X_test2)\n",
    "xgb_end_time_test = datetime.now() \n",
    "print('Stop testing {}'.format(str(xgb_end_time_test)))\n",
    "xgb_elapsed_time_test = xgb_end_time_test - xgb_start_time_test\n",
    "print('Elapsed testing {}'.format(str(xgb_elapsed_time_test)))\n",
    "xgb_cm = metrics.confusion_matrix(xgb_expected, xgb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy={}\".format(metrics.accuracy_score(xgb_expected, xgb_predicted)))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (\"XG-Boost\", metrics.classification_report(xgb_expected, xgb_predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % xgb_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plot_confusion_matrix(xgb_cm,classes=[0,1],cmap=plt.cm.Greys,normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = { \n",
    "#     'C': [6], \n",
    "#     'kernel': ['linear','rbf']\n",
    "# }\n",
    "# svm = SVC();\n",
    "# svm_start_time = datetime.now()\n",
    "# print('Start learning at {}'.format(str(svm_start_time)))\n",
    "# grid_svm = GridSearchCV(estimator=svm, param_grid=parameters, verbose=0);\n",
    "# grid_svm.fit(X_train, y_train);\n",
    "# svm_end_time = datetime.now() \n",
    "# print('Stop learning {}'.format(str(svm_end_time)))\n",
    "# svm_elapsed_time= svm_end_time - svm_start_time\n",
    "# print('Elapsed learning {}'.format(str(svm_elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_score_)\n",
    "print(grid_svm.best_estimator_)\n",
    "# print(grid_xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_svm.best_estimator_.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_expected = y_test\n",
    "svm_start_time_test = datetime.now()\n",
    "print('Start testing at {}'.format(str(svm_start_time_test)))\n",
    "svm_predicted = grid_svm.best_estimator_.predict(X_test)\n",
    "svm_end_time_test = datetime.now() \n",
    "print('Stop testing {}'.format(str(svm_end_time_test)))\n",
    "svm_elapsed_time_test = svm_end_time_test - svm_start_time_test\n",
    "print('Elapsed testing {}'.format(str(svm_elapsed_time_test)))\n",
    "svm_cm = metrics.confusion_matrix(svm_expected, svm_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy={}\".format(metrics.accuracy_score(svm_expected, svm_predicted)))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (\"Logistic Regression\", metrics.classification_report(svm_expected, svm_predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % svm_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm_cm,classes=[0,1],cmap=plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB();\n",
    "nb_start_time = datetime.now()\n",
    "print('Start learning at {}'.format(str(nb_start_time)))\n",
    "# grid_nb = GridSearchCV(estimator=nb, param_grid=parameters, verbose=0);\n",
    "nb.fit(X_train, y_train);\n",
    "nb_end_time = datetime.now() \n",
    "print('Stop learning {}'.format(str(nb_end_time)))\n",
    "nb_elapsed_time= nb_end_time - nb_start_time\n",
    "print('Elapsed learning {}'.format(str(nb_elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_score_)\n",
    "print(grid_svm.best_estimator_)\n",
    "# print(grid_xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid_nb.best_estimator_.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_expected = y_test\n",
    "nb_start_time_test = datetime.now()\n",
    "print('Start testing at {}'.format(str(nb_start_time_test)))\n",
    "nb_predicted = nb.predict(X_test)\n",
    "nb_end_time_test = datetime.now() \n",
    "print('Stop testing {}'.format(str(nb_end_time_test)))\n",
    "nb_elapsed_time_test = nb_end_time_test - nb_start_time_test\n",
    "print('Elapsed testing {}'.format(str(nb_elapsed_time_test)))\n",
    "nb_cm = metrics.confusion_matrix(nb_expected, nb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy={}\".format(metrics.accuracy_score(nb_expected, nb_predicted)))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (\"Logistic Regression\", metrics.classification_report(nb_expected, nb_predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % nb_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(nb_cm,classes=[0,1],cmap=plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test = [16 5 41.876248 -87.653065 10 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid_xgb.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test = np.array([[ 21.        ,   0.        ,  42.0122934 , -87.69971411,\n",
    "        15.        ,   9.        ]])\n",
    "print(scaler.transform(Test))\n",
    "Test2 = np.array([[-0.50714446,  0.70064672,  1.33995114, -1.07622397, -1.12694646, -0.47388072]])\n",
    "scaler.transform(Test2)\n",
    "print(xgb.predict(Test2))\n",
    "print(xgb.predict_proba(Test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = np.array([[ 21.        ,   0.        ,  42.0122934 , -87.69971411,15.        ,   9.        ]])\n",
    "# print(xgb.predict(scaler.transform[Test]))\n",
    "print(xgb.predict_proba(scaler.transform(Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open('./scaler.pkl', 'wb'))\n",
    "pickle.dump(xgb, open('./xgboost.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open('./scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Arrest Confusion matrix',\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
